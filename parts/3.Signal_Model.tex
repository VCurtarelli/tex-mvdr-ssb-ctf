\section{Signal Model and Beamforming}
\label{sec:signal_model}

Let there be a device that consists of $M$ sensors and a loudspeaker (LS) in a reverberant environment. In this setting there also are a desired source, an interfering source, and uncorrelated noise impinging at each sensor, all traveling with a speed $c$. For simplicity we assume that all sources are spatially stationary, although this condition can be easily removed.

We denote $y_m[n]$ as the signal at the $m$-th sensor, being defined as
\begin{equation}
	\label{eq:sec3:time_model_basic}
	y_m[n] = h_m[n] \ast x[n] + g_m[n] \ast w[n] + e_m[n] \ast s[n] + r_m[n]
\end{equation}
in which $h_m[n]$ is the impulse response between the desired source and the $m$-th sensor ($1 \leq m \leq M$), with $x[n]$ being the desired source's signal; similarly for the interfering noise $w[n]$ and its IR $g_m[n]$, and th speaker's signal $s[n]$ and its IR $e_m[n]$; and $r_m[n]$ is the uncorrelated noise.

We let $m'$ be the reference sensor's index, for simplicity assume $m' = 1$, and also $x_1[n] = h_1[n] \ast x[n]$ (and similarly for $v_1[n]$ and $s_1[n]$). We define $a_m[n]$ as the \textit{relative} impulse response between the desired signal (at the reference sensor) and the $m$-th sensor, such that
\begin{equation}
	a_m[n] \ast x_1[n] = h_m[n] \ast x[n]
\end{equation}
We similarly define $b_m[n]$ such that $b_m[n] \ast w_1[n] = g_m[n] \ast w[n]$, and $c_m[n]$ from $e_m[n]$ and $s[n]$. Therefore, \cref{eq:sec3:time_model_basic} becomes
\begin{equation}
	\label{eq:sec3:time_model_relative}
	y_m[n] = a_m[n] \ast x_1[n] + b_m[n] \ast w_1[n] + c_m[n] \ast s_1[n] + r_m[n]
\end{equation}
Here, the impulse responses ($a_m[n]$, $b_m[n]$, $c_m[n]$) can be non-causal, depending on the direction of arrival and features of the reverberant environment.

We use a time-frequency transform (such as the STFT or SSBT, as in \cref{sec:stft_and_ssbt}) with the convolutive transfer-function (CTF) model \cite{talmon_relative_2009} to obtain our time-frequency signal model,
\begin{equation}
	\label{eq:sec3:time-freq_model_conv}
	Y_m[l,k] = A_m[l,k] \ast X_1[l,k] + B_m[l,k] \ast W_1[l,k] + C_m[l,k] \ast S_1[l,k] + R_m[l,k]
\end{equation}
where $Y_m[l,k]$ is the transform of $y_m[n]$ (resp. all other signals); $l$ and $k$ are the window (or decimated-time) and bin indexes, with $0 \leq k \leq K-1$; and the convolution is in the window-index axis.

Using that $A_m[l,k]$ is a finite (possibly truncated) response with $L_A$ windows, then
\begin{equation}
	\label{eq:sec3:convert_convol_matmult}
	A_m[l,k] \ast X_1[l,k] = \tr{\bva{m}}[k] \bvx{1}[l,k]
\end{equation}
in which
\begin{subalign}
	\bva{m}[k] & = \tr{\tup{ {A_m[-\Delta,k]} ,, {A_m[0,k]} , , {A_m[L_B-\Delta-1,k]} }} \\
	\bvx{1}[l,k] & = \tr{\tup{ {X_1[l+\Delta,k]} , , { X_1[l,k]} , , {X_1[l-L_B+\Delta+1,k]} }} \label{subeq:sec3:def_bvx1lk}
\end{subalign}
and in the same way we define $\bvb{m}[k]$, $\bvw{1}[l,k]$, $\bvd{m}[k]$ and $\bvs{1}[l,k]$. Note that $\bva{m}[k]$ and $\bvb{m}[k]$ don't depend on the index $l$, given the spatial stationarity assumption. Also, $\Delta$ is the number of non-causal windows in the reference sensor necessary to capture the whole signal. With this, \cref{eq:sec3:time-freq_model_conv} becomes
\begin{equation}
	\label{eq:sec3:time-freq_model_mult1}
	Y_m[l,k] = \tr{\bva{m}}[k] \bvx{1}[l,k] + \tr{\bvb{m}}[k] \bvw{1}[l,k] + \tr{\bvc{m}}[k] \bvs{1}[l,k] + R_m[l,k]
\end{equation}

Vectorizing the signals sensor-wise, we finally get
\begin{equation}
	\label{eq:sec3:bvylk_vectorized}
	\bvy[l,k] = \bvA[k] \bvx{1}[l,k] + \bvB[k] \bvw{1}[l,k] + \bvC[k] \bvs{1}[l,k] + \bvr[l,k]
\end{equation}
where
\begin{equation}
	\bvy[l,k] = \tr{\tup{ {y_1[l,k]},,{y_M[l,k]} }}
\end{equation}
and similarly for the other variables. In this situation, $\bvA[k]$, $\bvB[k]$ and $\bvC[k]$ are $\sz{M}{L_A}$, $\sz{M}{L_B}$ and $\sz{M}{L_C}$ matrices respectively; $\bvx{1}[l,k]$, $\bvw{1}[l,k]$ and $\bvs{1}[l,k]$ are $\sz{L_A}{1}$, $\sz{L_B}{1}$ and $\sz{L_C}{1}$ vectors respectively; and $\bvy[l,k]$ and $\bvr[l,k]$ are $\sz{M}{1}$ vectors.

\subsection{Reverb-aware formulation}\label{subsec:sec3:reverb-rejecting_formulation}
Let $l = 0$ be the desired window which we would like to retrieve from the signal $\bvA[k] \bvx{1}[l,k]$. We can write $\bvA[k] \bvx{1}[l,k]$ as
\begin{equation}
	\label{eq:sec3:bvAk_bvx1lk_separated}
	\bvA[k] \bvx{1}[l,k] = \bvd{x}[k] X_1[l,k] + \bvq[l,k]
\end{equation}
where $X_1[l,k]$ is the desired speech signal, and $\bvq[l,k]$ is an undesired component, uncorrelated to $X_1[l,k]$. Through a similar process as exposed in \cite{bai_acoustic_2013} (sec. 7.1.1) (see \cref{app:derivation_correct_sep} for details), we can deduce that $\bvd{x}[k]$ can be defined as
\begin{equation}
	\bvd{x}[k] = \frac{\sum_{i} \bva{m}[k]_{i} \sum_{n=0}^{K-1-\abs{i\O}} w[n] w[n+ \abs{i\O}]}{\sum_{n'=0}^{K-1}w[n']^2}
\end{equation}
in which $w[n]$ and $\O$ are the window-function and the decimation factor used for the time-frequency transform; and $\bva{m}[k]_{i}$ is the $(\Delta+i)$-th element of $\bva{m}[k]$. From \cref{app:ssbt_convolution}, we also have that $-\floor{\nicefrac{(K-1)}{\O}} \leq i \leq \floor{\nicefrac{(K-1)}{\O}}$.

Note that $\bvd{x}[k] X_1[l,k]$ also consists of some reverberation, since $x_1[n] = h_1[n] \ast x[n]$ is the desired signal at the reference sensor and not at source, therefore being affected by the environment. However, this formulation allows us to better estimate the influence of the neighboring time-frequency windows over the desired signal, given their overlap.
%\newpage
%Let the $\Delta$-th column of $\bvA[k]$ (equivalent to $l=0$) be the desired-speech frequency response $\bvd{x}[k]$, with the rest comprising an undesired component. We therefore write
%\begin{equations}
%	\label{eq:sec3:bvAk_bvx1lk_separated}
%	\bvA[k] \bvx{1}[l,k]
%	& = \bvd{x}[k] X_1[l,k] + \sum_{\substack{l'=-\Delta \\ l' \neq 0}}^{L_B-\Delta-1} \bvpsi_{A,l'}[k] X_1[l-l',k] \\
%	& = \bvd{x}[k] X_1[l,k] + \bvq[l,k]
%\end{equations}
%where $\bvpsi_{B,l'}[k]$ is the $l'$-th column of $\bvA[k]$. With this, $\bvd{x}[k] X_1[l,k]$ is the desired speech component of $\bvA[k] \bvx{1}[l,k]$; and $\bvq[l,k]$ (the summation over $l' \neq 0$) is the undesired component, or reverberation signal. Note that $\bvd{x}[k] X_1[l,k]$ also consists of some reverberation, since $x_1[n] = h_1[n] \ast x[n]$ is the desired signal at the reference sensor, therefore after going through the environment.

It's important to have in mind the sensor delay and window length. If the time for the signal to travel from the reference to the farthest sensor exceeds the window length (in seconds), different windows may represent the desired speech, for each sensor. This isn't a problem if $\frac{\bar{\delta}}{c} < \frac{K}{f_s}$, where $\bar{\delta}$ is the largest reference-to-sensor distance among all sensors.

Using \cref{eq:sec3:bvAk_bvx1lk_separated} we define $\bvv[l,k]$ as the undesired signal (undesired speech components + speaker signal + interfering source + uncorrelated noise),
\begin{equation}
	\label{eq:sec3:def_undes_sig_bvwlk}
	\bvv[l,k] = \bvq[l,k] + \bvB[k] \bvw{1}[l,k] + \bvC[k] \bvs{1}[l,k] + \bvr[l,k]
\end{equation}
and therefore
\begin{equation}
	\label{eq:sec3:time-freq_model_final}
	\bvy[l,k] = \bvd{x}[k] X_1[l,k] + \bvv[l,k]
\end{equation}

We estimate the desired signal at reference $X_1[l,k]$ as $Z[l,k]$ through a filter $\bvf[l,k]$, such that
\begin{equations}
	Z[l,k]
	& = \he{\bvf}[l,k] \bvy[l,k] \\
	& \approx X_1[l,k]
\end{equations}
with $\he{(\cdot)}$ being the transposed-complex-conjugate operator. Since the source signals' properties can vary over time, so can the filter, adapting to the environment.

To minimize the variance of the output signal while obeying the distortionless constraint $\he{\bvf}[l,k] \bvd{x}[l,k] = 1$, a Minimum-Power Distortionless Response (MPDR) beamformer will be used, it being defined as

\begin{equation}
	\label{eq:sec3:minimization_problem_mpdr}
	\bvf_{\mpdr}[l,k] = \min_{\bvf[l,k]} \he{\bvf[l,k]} \Corr{\bvy}[l,k] \bvf[l,k]~\text{s.t.}~\he{\bvf}[l,k] \bvd{x}[l,k] = 1
\end{equation}
where $\Corr{\bvy}[l,k]$ is the correlation matrix of the observed signal $\bvy[l,k]$. The solution to this minimization problem 
\begin{equation}
	\label{eq:sec3:solution_mpdr_beamformer}
	\bvf{\mpdr}[l,k] = \frac{\inv{\Corr{\bvy}}[l,k] \bvd{x}[l,k]}{\he{\bvd{x}}[k] \inv{\Corr{\bvy}}[l,k] \bvd{x}[k]}
\end{equation}

\subsection{Performance metrics}

Given the three main goals of the beamformer being the cancellation of the LS signal, the minimization of the overall undesired signal, and the maintenance of the desired signal (through the distortionless constraint), our choice of metrics will reflect these objectives. We define $S_f[l,k] = \he{\bvf}[l,k] \bvs{1}[l,k]$, $X_f[l,k] = \he{\bvf}[l,k] \bvx{1}[l,k]$ and $V_f[l,k] = \he{\bvf}[l,k] \bvv{1}[l,k]$ as the filtered-LS, filtered-desired and filtered-undesired signals, respectively. Unless stated otherwise, the metrics used are broadband.

The LS signal's minimization will be measured via the echo-return loss enhancement $\erle[l]$, defined as
\begin{equation}
	\erle[l] = \frac{\sum_{k}\abs{S_1[l,k]}^2}{\sum_{k}\abs{S_f[l,k]}^2}
\end{equation}
The desired signal distortion index $\dsdi[l]$ will be used to assess the distortion on the desired signal, given by
\begin{equation}
	\dsdi[l] = \frac{\sum_{k}\abs{X_1[l,k] - X_f[l,k]}^2}{\sum_{k}\abs{X_1[l,k]}^2}
\end{equation}

Finally, the minimization of the overall undesired signal will be measured using the noise signal reduction factor (NSRF), such that
\begin{equation}
	\nsrf[l] = \frac{\sum_{k} \abs{V_1[l,k]}^2 }{\sum_{k} \abs{V_f[l,k]}^2 }
\end{equation}
in which $V_1[l,k]$ is the undesired signal at the reference sensor.


