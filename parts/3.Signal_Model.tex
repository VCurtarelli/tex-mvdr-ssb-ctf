\section{Signal Model and Beamforming}
\label{sec:signal_model}

Let there be a generic sensor array within a reverberant environment, it being comprised of $M$ sensors. In this setting there also are a desired and an interfering sources (namely $x[n]$ and $v[n]$), and also uncorrelated noise $r_m[n]$ at each sensor, all traveling with a speed $c$. We assume that the sources are spatially stationary, and all discrete signals were sampled with the same sampling frequency $f_s$.

We denote $h_m[n]$ as the room impulse response between the desired source and the $m$-th sensor ($1 \leq m \leq M$). We similarly define $g_m[n]$ for the interfering source. From this, we write $y_m[n]$ as the observed signal at the $m$-th sensor as
\begin{equation}
	\label{eq:sec3:time_model_basic}
	y_m[n] = h_m[n] \ast x[n] + g_m[n] \ast v[n] + r_m[n]
\end{equation}
We let $m'$ be the reference sensor's index, for simplicity assume $m'=1$. We let $x_1[n] = h_1[n] \ast x[n]$ (and similarly for $v_1[n]$). $b_m[n]$ is the \textit{relative} impulse response between the desired signal (at the reference sensor) and the $m$-th sensor, define such that
\begin{equation}
	b_m[n] \ast x_1[n] = h_m[n] \ast x[n]
\end{equation}
We similarly define $c_m[n]$ such that $c_m[n] \ast v_1[n] = g_m[n] \ast v[n]$. Therefore, \cref{eq:sec3:time_model_basic} becomes
\begin{equation}
	\label{eq:sec3:time_model_relative}
	y_m[n] = b_m[n] \ast x_1[n] + c_m[n] \ast v_1[n] + r_m[n]
\end{equation}
Here, the impulse responses $b_m[n]$ and $c_m[n]$ can be non-causal, depending on the direction of arrival and features of the reverberant environment.

We can use a time-frequency transform (here the STFT or the SSBT, both exposed in \cref{sec:stft_and_ssbt}) with the CTF model \cite{talmon_relative_2009} to get our time-frequency signal model,
\begin{equation}
	\label{eq:sec3:time-freq_model_conv}
	Y_m[l,k] = B_m[l,k] \ast X_1[l,k] + C_m[l,k] \ast V_1[l,k] + R_m[l,k]
\end{equation}
where $Y_m[l,k]$ is the transform of $y_m[n]$ (resp. all other signals); $l$ is the window index, and $k$ the bin index, with $0 \leq k \leq K-1$; and the convolution is in the window-index axis.

Using that $B_m[l,k]$ is a finite (possibly truncated) response with $L_B$ windows, then
\begin{equation}
	B_m[l,k] \ast X_1[l,k] = \tr{\bvb{m}}[k] \bvx{1}[l,k]
\end{equation}
in which
\begin{subalign}
	\bvb{m}[k] & = \tr{\tup{ {B_m[-\Delta,k]} ,, {B_m[0,k]} , , {B_m[L_B-\Delta-1,k]} }} \\
	\bvx{1}[l,k] & = \tr{\tup{ {X_1[l+\Delta,k]} , , { X_1[l,k]} , , {X_1[l-L_B+\Delta+1,k]} }} \label{subeq:sec3:def_bvx1lk}
\end{subalign}
and in the same way we define $\bvc{m}[k]$ and $\bvv{1}[l,k]$. Note that $\bvb{m}[k]$ and $\bvc{m}[k]$ don't depend on the index $l$, since neither the environment nor the sources' positions change over time. With this, \cref{eq:sec3:time-freq_model_conv} becomes
\begin{equation}
	\label{eq:sec3:time-freq_model_mult1}
	Y_m[l,k] = \tr{\bvb{m}}[k] \bvx{1}[l,k] + \tr{\bvc{m}}[k] \bvv{1}[l,k] + R_m[l,k]
\end{equation}

Vectorizing the signals sensor-wise, we finally get
\begin{equation}
	\label{eq:sec3:bvylk_vectorized}
	\bvy[l,k] = \bvB[k] \bvx{1}[l,k] + \bvC[k] \bvv{1}[l,k] + \bvr[l,k]
\end{equation}
where
\begin{equation}
	\bvy[l,k] = \tr{\tup{ {y_1[l,k]},,{y_M[l,k]} }}
\end{equation}
and similarly for the other variables. In this situation, $\bvB[k]$ and $\bvC[k]$ are $\sz{M}{L_B}$ and $\sz{M}{L_C}$ matrices respectively; $\bvx{1}[l,k]$ and $\bvv{1}[l,k]$ are $\sz{L_B}{1}$ and $\sz{L_C}{1}$ vectors respectively; and $\bvy[l,k]$ and $\bvr[l,k]$ are $\sz{M}{1}$ vectors.

\subsection{Reverb-rejecting formulation}\label{subsec:sec3:reverb-rejecting_formulation}
Let the $\Delta$-th column of $\bvB[k]$ (equivalent to $l=0$) be the desired-speech frequency response (named $\bvd{x}[k]$), with the rest comprising an undesired component. We therefore write
\begin{equation}
	\label{eq:sec3:bvBk_bvx1lk_separated}
	\bvB[k] \bvx{1}[l,k] = \bvd{x}[k] X_1[l,k] + \sum_{\substack{l'=-\Delta \\ l' \neq 0}}^{L_B-\Delta-1} \bvp{B,l'}[k] X_1[l-l',k]
\end{equation}
where $\bvp{B,l'}[k]$ is the $l'$-th column of $\bvB[k]$. With this, $\bvd{x}[k] X_1[l,k]$ is the desired speech component of $\bvB[k] \bvx{1}[l,k]$, and the summation over $l'$ is the undesired component. We will call $\bvd{x}[k]$ the desired-speech frequency response.

It's important to have in mind the sensor delay and window length. If the time for the signal to travel from the reference to the farthest sensor exceeds the window length (in seconds), multiple windows may represent the desired speech. This isn't a problem if $\frac{\delta}{c} < \frac{K}{f_s}$, where $\delta$ is the biggest reference-to-sensor distance, and $K$ is the window length.

Using \cref{eq:sec3:bvBk_bvx1lk_separated} we define $\bvw[l,k]$ as the undesired signal (undesired speech components + interfering source + noise),
\begin{equation}
	\label{eq:sec3:def_undes_sig_bvwlk}
	\bvw[l,k] = \sum_{\substack{l'=-\Delta \\ l' \neq 0}}^{L_B-\Delta-1} \bvp{B,l'}[k] X_1[l-l',k] + \bvC[k] \bvv{1}[l,k] + \bvr[l,k]
\end{equation}
and therefore
\begin{equation}
    \label{eq:sec3:time-freq_model_final}
	\bvy[l,k] = \bvd{x}[k] X_1[l,k] + \bvw[l,k]
\end{equation}
%Note that in \cref{eq:sec3:time-freq_model_final,eq:sec3:def_undes_sig_bvwlk} we can treat each window of the incoming signals as a different source, with its own frequency response. This facilitates the use of known methods for signal enhancement.

%For simplicity we assume that all windows of $X_{1}[l,k]$ are independent of one-another, and that $\bvw[l,k]$ is independent of $\bvd{x}[k] X_1[l,k]$. This isn't strictly true, given both the time-frequency windowing process and the reverberant behavior of the environment.

We estimate the desired signal at reference through a filter $\bvf[l,k]$, such that
\begin{equations}
	Z[l,k]
	& = \he{\bvf}[l,k] \bvy[l,k] \\
	& \approx X_1[l,k]
\end{equations}
with $\he{(\cdot)}$ being the transposed-complex-conjugate operator. Since the source signals' properties can vary over time, so can the filter, in order to adapt to the environment.

In order to minimize $\bvw[l,k]$ the MVDR beamformer \cite{erdogan_improved_2016} will be used, being given by
\begin{equation}
	\label{eq:sec3:minimization_problem_mvdr}
	\bvf_{\mvdr}[l,k] = \min_{\bvf[l,k]} \he{\bvf[l,k]} \Corr{\bvy}[l,k] \bvf[l,k]~\text{s.t.}~\he{\bvf}[l,k] \bvd{x}[k] = 1
\end{equation}
in which $\he{\bvf}[l,k] \bvd{x}[k] = 1$ is the distortionless constraint, and $\Corr{\bvy}[l,k]$ is the correlation matrix of the observed signal $\bvy[l,k]$. This formulation is preferred over the one using $\Corr{\bvw}[l,k]$ given the observed signal's availability.

The solution to \cref{eq:sec3:minimization_problem_mvdr} is
\begin{equation}
	\label{eq:sec3:solution_mvdr_beamformer}
	\bvf{\mvdr}[l,k] = \frac{ \inv{\Corr{\bvy}}[l,k] \bvd{x}[k] }{ \he{\bvd{x}}[k] \inv{\Corr{\bvy}}[l,k] \bvd{x}[k] }
\end{equation}

\subsection{Beamformer metrics}

Considering the problem, the relevant metrics are the narrowband gain in signal-to-noise ratio (SNR) and narrowband desired signal reduction factor (DSRF), respectively given by
\begin{equation}
	\gsnr[l,k] = \var{V_1}[l,k] \frac{ \abs{\he{\bvf}[l,k] \bvd{x}[k]}^2}{ \he{\bvf}[l,k] \Corr{\bvw}[l,k] \bvf[l,k] }
\end{equation}
\begin{equation}
	\dsrf[l,k] = \frac{1}{\abs{\he{\bvf}[l,k] \bvd{x}[k]}^2}
\end{equation}
It is easy to see that if $\dsrf[l,k] = 1$ then the distortionless constraint is satisfied. We can also define the window-averaged gain in SNR and DSRF as
\begin{equation}
	\gsnr[k] = \frac{1}{L_Z}\sum_{l=0}^{L_Z-1} \text{gSNR}[l,k]
\end{equation}
\begin{equation}
	\dsrf[k] = \frac{1}{L_Z}\sum_{l=0}^{L_Z-1} \dsrf[l,k]
\end{equation}
with $L_Z$ being the number of windows of $Z[l,k]$; and the broadband SNR gain and DSRF, given by
\begin{equation}
	\gsnr = \frac{1}{K} \sum_{k=0}^{K-1} \gsnr[k]
\end{equation}
\begin{equation}
	\dsrf = \frac{1}{K} \sum_{k=0}^{K-1} \dsrf[k]
\end{equation}